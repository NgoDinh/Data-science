{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pu_learning_segmentation",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/NgoDinh/Data-science/blob/master/pu_learning_segmentation.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "_CZ2DjX7PP8B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import psycopg2 as pg\n",
        "from dateutil import parser\n",
        "from dateutil.relativedelta import relativedelta\n",
        "import time\n",
        "import sys\n",
        "import math\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import datetime\n",
        "\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# function to query data from database\n",
        "#=============================================================#\n",
        "def query_data(target_date, date_end=False, positive = False):\n",
        "      \n",
        "    date_start = parser.parse(target_date) + relativedelta(days=-1)\n",
        "    date_start = date_start.strftime('%Y-%m-%d')\n",
        "    \n",
        "    if date_end:\n",
        "        date_end = date_end\n",
        "    else:\n",
        "        date_end = parser.parse(target_date) + relativedelta(days=1)\n",
        "        date_end = date_end.strftime('%Y-%m-%d')\n",
        "            \n",
        "    extra_query = '''\n",
        "    and so.partner_id in (select partner_id from sale_order where date_order between '%s' and '%s' \n",
        "                           UNION\n",
        "                          select partner_id from pos_order where date_order between '%s' and '%s'\n",
        "                            )\n",
        "    '''%(date_start, date_end, date_start, date_end)\n",
        "    \n",
        "    if positive:\n",
        "        extra = extra_query\n",
        "        tmp = parser.parse(target_date) + relativedelta(days=-2)\n",
        "        target_date = tmp.strftime('%Y-%m-%d')\n",
        "    else:\n",
        "        extra = \"\"\n",
        "        #delete when launch\n",
        "        tmp = parser.parse(target_date) + relativedelta(days=-2)\n",
        "        target_date = tmp.strftime('%Y-%m-%d')\n",
        "    \n",
        "    get_total_customer='''\n",
        "    Select\n",
        "        tmp.id,\n",
        "        tmp.customer_name,\n",
        "        tmp.gioi_tinh_id,\n",
        "        tmp.phone,\n",
        "        tmp.time_life,\n",
        "        tmp.check_info,\n",
        "        date('%s')-date(max(tmp.create_date)) as last_time,\n",
        "        sum(tmp.total_amount) as total_amount,\n",
        "        sum(tmp.qty) as total_product,\n",
        "        count(distinct tmp.name) as total_order,\n",
        "        case \n",
        "        when \n",
        "            count(distinct tmp.name) = 1 then 9999\n",
        "        else\n",
        "            tmp.time_life / count(distinct tmp.name) \n",
        "        end as rebuy_time,\n",
        "        sum(tmp.men) as total_men_product,\n",
        "        sum(tmp.women) as total_women_product,\n",
        "        sum(tmp.others) as total_y_product,\n",
        "        count(distinct online) as online,\n",
        "        count(distinct offline) as offline\n",
        "    from\n",
        "        (select \n",
        "            rp.id,\n",
        "            rp.name customer_name,\n",
        "            rp.gioi_tinh_id,\n",
        "            rp.phone,\n",
        "            date('%s') - date(rp.create_date) as time_life,\n",
        "            so.create_date,\n",
        "            Case\n",
        "            When \n",
        "                (rp.birthdate_date is not null and rp.email !='' and (date('%s')-date(rp.birthdate_date)) < 36135) then 1\n",
        "            else \n",
        "                0\n",
        "            end as check_info,\n",
        "            line.price_unit * line.product_uom_qty as total_amount,\n",
        "            line.product_uom_qty as qty,\n",
        "            so.name,pp.default_code,\n",
        "            Case when upper(pp.default_code) like 'M%%' then line.product_uom_qty else 0 end men,\n",
        "            Case when upper(pp.default_code) like 'W%%' then line.product_uom_qty else 0 end women,\n",
        "            Case when (upper(pp.default_code) not like 'M%%' and upper(pp.default_code) not like 'W%%') then line.product_uom_qty else 0 end others,\n",
        "            so.name online,\n",
        "            null offline\n",
        "        from\n",
        "            sale_order as so\n",
        "        inner join res_partner as rp on rp.id = so.partner_id\n",
        "        inner join sale_order_line as line on line.order_id = so.id\n",
        "        inner join product_product pp on pp.id = line.product_id\n",
        "        INNER JOIN product_template as pt ON pt.id = pp.product_tmpl_id\n",
        "        where\n",
        "            rp.phone is not Null\n",
        "            and (left(rp.phone,4) in ('0162','0163','0164','0165','0166','0167','0168','0169','0120','0121','0122','0126','0128','0123','0124','0125','0127','0129','0188','0186')\n",
        "            or left(rp.phone,3) in ('086','096','097','098','090','093','091','094','092','088')\n",
        "            or left(rp.phone,5) in ('08966'))\n",
        "            and so.name not like '%%-%%'\n",
        "            AND (so.section_id NOT IN (select id from crm_case_section where name like 'Dir%%') or so.section_id IS NULL)\n",
        "            AND so.state != 'cancel'\n",
        "            and pt.type NOT LIKE 'service%%'\n",
        "            and (date('%s')-date(so.date_order))>0 %s\n",
        "            \n",
        "        UNION\n",
        "\n",
        "        select \n",
        "            rp.id,\n",
        "            rp.name customer_name,\n",
        "            rp.gioi_tinh_id,\n",
        "            rp.phone,\n",
        "            date('%s') - date(rp.create_date) as time_life,\n",
        "            so.create_date,\n",
        "            Case\n",
        "            When \n",
        "                (rp.birthdate_date is not null and rp.email !='' and (date('%s')-date(rp.birthdate_date)) < 36135) then 1\n",
        "            else \n",
        "                0\n",
        "            end as check_info,\n",
        "            line.price_unit * line.qty as total_amount,\n",
        "            line.qty,\n",
        "            so.name,pp.default_code,\n",
        "            Case when upper(pp.default_code) like 'M%%' then line.qty else 0 end men,\n",
        "            Case when upper(pp.default_code) like 'W%%' then line.qty else 0 end women,\n",
        "            Case when (upper(pp.default_code) not like 'M%%' and upper(pp.default_code) not like 'W%%') then line.qty else 0 end others,\n",
        "            null online,\n",
        "            so.name offline\n",
        "\n",
        "        from \n",
        "            pos_order as so\n",
        "        inner join res_partner as rp on rp.id = so.partner_id\n",
        "        inner join pos_order_line as line on line.order_id = so.id\n",
        "        inner join product_product pp on pp.id = line.product_id\n",
        "        INNER JOIN product_template as pt ON pt.id = pp.product_tmpl_id\n",
        "        where\n",
        "            rp.phone is not Null\n",
        "            and (left(rp.phone,4) in ('0162','0163','0164','0165','0166','0167','0168','0169','0120','0121','0122','0126','0128','0123','0124','0125','0127','0129','0188','0186')\n",
        "            or left(rp.phone,3) in ('086','096','097','098','090','093','091','094','092','088')\n",
        "            or left(rp.phone,5) in ('08966'))\n",
        "            --and so.name not like '%%-%%'\n",
        "            --AND (so.section_id NOT IN (select id from crm_case_section where name like 'Dir%%') or so.section_id IS NULL)\n",
        "            AND so.state != 'cancel'\n",
        "            and pt.type NOT LIKE 'service%%'\n",
        "            and (date('%s')-date(so.date_order))>0 %s\n",
        "            ) as tmp\n",
        "    group by 1,2,3,4,5,6\n",
        "    '''%(target_date,target_date,target_date,target_date,extra,target_date,target_date,target_date,extra)\n",
        "    \n",
        "    engine = pg.connect('postgresql://odoo:odoo@***/*')\n",
        "    df = pd.read_sql(get_total_customer,engine)\n",
        "    df['average_amount'] = df['total_amount']/df['total_order']\n",
        "    df['average_product'] = df['total_product']/df['total_order']\n",
        "    \n",
        "    if positive:\n",
        "        df['target'] = 1\n",
        "    else:\n",
        "        df['target'] = 0\n",
        "    \n",
        "    def check_gender(row):\n",
        "        if np.isnan(row['gioi_tinh_id']) == False:\n",
        "            val = row['gioi_tinh_id']\n",
        "        else:\n",
        "            if row['customer_name'].lower().startswith(('chú', 'chu', 'bac', 'bác', 'a')):\n",
        "                val = 2\n",
        "            elif row['customer_name'].lower().startswith('c'):\n",
        "                val = 1\n",
        "            else:\n",
        "                val = 0\n",
        "        return val\n",
        "\n",
        "    df['gender'] = df.apply(check_gender, axis=1)\n",
        "    df = df.drop(['customer_name', 'gioi_tinh_id'], axis=1)\n",
        "    \n",
        "    return df, get_total_customer\n",
        "  \n",
        "# get data by condition\n",
        "#=============================================================#\n",
        "\n",
        " def get_data(target_date, date_end=False):\n",
        "    \n",
        "    ''' get data from database and then concat unlabled data to positive data'''\n",
        "    \n",
        "    start_time = time.time()\n",
        "    data_u, query_u = query_data(target_date)\n",
        "    target_date_revise = parser.parse(target_date) + relativedelta(years=-1)\n",
        "    target_date_revise = target_date_revise.strftime('%Y-%m-%d')\n",
        "    \n",
        "    if date_end:\n",
        "        date_end_revise = parser.parse(date_end) + relativedelta(years=-1)\n",
        "        date_end_revise = date_end_revise.strftime('%Y-%m-%d')\n",
        "    else:\n",
        "        date_end_revise = date_end\n",
        "        \n",
        "    data_p, query_p = query_data(target_date_revise, date_end_revise, positive=True)\n",
        "    \n",
        "    def id_new(row):\n",
        "        return str(row['id'])+'-'+str(row['target'])\n",
        "    \n",
        "    data_p['id_new'] = data_p.apply(id_new, axis=1)\n",
        "    data_u['id_new'] = data_u.apply(id_new, axis=1)\n",
        "    \n",
        "    data_p = data_p.set_index('id_new')\n",
        "    data_u = data_u.set_index('id_new')\n",
        "    \n",
        "    data_p = data_p.drop(['id'], axis=1)\n",
        "    data_u = data_u.drop(['id'], axis=1)\n",
        "#     data_low = data_u[data_u['id']<100000]\n",
        "#     data_hight = data_u[data_u['id']>100000]\n",
        "    \n",
        "    data = pd.concat([data_u, data_p])\n",
        "#     data_low = pd.concat([data_low, data_p])\n",
        "#     data_hight = pd.concat([data_hight, data_p])\n",
        "    \n",
        "#     data_low = data_low.drop(['id'], axis=1)\n",
        "#     data_hight = data_hight.drop(['id'], axis=1)\n",
        "#     data_low = data_low.drop(['phone'], axis=1)\n",
        "#     data_hight = data_hight.drop(['phone'], axis=1)\n",
        "    \n",
        "    phone_list = data['phone']\n",
        "    data = data.drop(['phone'], axis=1)\n",
        "    \n",
        "    print(query_u)\n",
        "    print('='*20)\n",
        "    print(query_p)\n",
        "    print(time.time() - start_time)\n",
        "\n",
        "    return data, data_u, phone_list\n",
        "  \n",
        "# use pu_learning to train data\n",
        "#=============================================================#\n",
        "  \n",
        "  def train_data(estimator, data, ratio=1):\n",
        "    ''' If ratio is percentage of unlabed data have been used to train'''\n",
        "    \n",
        "    start_time = time.time()\n",
        "    X = data.drop(['target'], axis=1)\n",
        "    y = data['target']\n",
        "\n",
        "    iP = y[y > 0].index\n",
        "    iU = y[y <= 0].index\n",
        "    if ratio > 1:\n",
        "        n_estimators=ratio\n",
        "    else:\n",
        "        n_estimators = math.ceil(len(iU)/len(iP)*ratio)\n",
        "\n",
        "\n",
        "    num_oob = pd.DataFrame(np.zeros(shape = y.shape), index = y.index)\n",
        "    sum_oob = pd.DataFrame(np.zeros(shape = y.shape), index = y.index)\n",
        "\n",
        "    for e in range(n_estimators):\n",
        "        # Get a bootstrap sample of unlabeled points for this round\n",
        "        ib = np.random.choice(iU, replace = True, size = len(iP))\n",
        "\n",
        "        # Find the OOB data points for this round\n",
        "        i_oob = list(set(iU) - set(ib))\n",
        "\n",
        "        # Get the training data (ALL positives and the bootstrap\n",
        "        # sample of unlabeled points) and build the tree\n",
        "        Xb = X[y > 0].append(X.loc[ib])\n",
        "        yb = y[y > 0].append(y.loc[ib])\n",
        "        estimator.fit(Xb, yb)\n",
        "\n",
        "        # Record the OOB scores from this round\n",
        "        sum_oob.loc[i_oob, 0] += estimator.predict_proba(X.loc[i_oob])[:,1]\n",
        "        num_oob.loc[i_oob, 0] += 1\n",
        "\n",
        "        i = int((e+1)/n_estimators*100)\n",
        "        sys.stdout.write('\\r')\n",
        "        # the exact output you're looking for:\n",
        "        sys.stdout.write(\"[%-100s] %d%%\" % ('='*(i),i))\n",
        "        sys.stdout.flush()\n",
        "\n",
        "    results = sum_oob / num_oob\n",
        "    num_oob['score'] = sum_oob\n",
        "    num_oob['result'] = results\n",
        "    \n",
        "    print(\"\\n--- %s_%s seconds to Done with %s ---\" %(str(estimator)[:1],time.time() - start_time, n_estimators))\n",
        "    \n",
        "    return num_oob \n",
        "  \n",
        "# ensemble random forest and knn\n",
        "#=============================================================#\n",
        "  \n",
        "  def ensemble_train_data(data, ratio, max_depth=3, n_neighbors=10, size=10000, knn_size=0.3):\n",
        "    \n",
        "    from sklearn.neighbors import KNeighborsClassifier\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "    \n",
        "    knn = KNeighborsClassifier(n_neighbors=n_neighbors, n_jobs=-1)\n",
        "    knn_result = train_data(knn, data, ratio = ratio)\n",
        "    knn_result['tmp'] = knn_result.index\n",
        "    knn_result['id'] = knn_result['tmp'].apply(lambda x: int(x[:-2]))\n",
        "    knn_result = knn_result[(knn_result['id']<100000)&(knn_result['score']>0)]\n",
        "    knn_result = knn_result.sort_values(['result'], ascending=False)\n",
        "    knn_result = knn_result.head(round(size*knn_size))\n",
        "\n",
        "    rc = RandomForestClassifier(max_depth=max_depth, n_jobs=-1, n_estimators=20)\n",
        "    rc_result = train_data(rc, data, ratio = ratio)\n",
        "    rc_result['tmp'] = rc_result.index\n",
        "    rc_result['id'] = rc_result['tmp'].apply(lambda x: int(x[:-2]))\n",
        "    rc_result = rc_result[(rc_result['id']>100000)&(rc_result['score']>0)]\n",
        "    rc_result = rc_result.sort_values(['result'], ascending=False)\n",
        "    rc_result = rc_result.head(round(size*(1-knn_size)))\n",
        "\n",
        "    result = pd.concat([knn_result, rc_result])\n",
        "\n",
        "#     writer = pd.ExcelWriter('E%s_%s_output_%s.xlsx'%(ratio, knn_size,datetime.datetime.now()))\n",
        "#     result.to_excel(writer,'result')\n",
        "#     knn_result.to_excel(writer,'knn_result')\n",
        "#     rc_result.to_excel(writer,'rc_result')\n",
        "#     writer.save()\n",
        "    \n",
        "    print(\"Done!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
        "    \n",
        "    return result, size\n",
        "\n",
        "  \n",
        "# function to test model\n",
        "#=============================================================#\n",
        "  \n",
        "  def test_model(data_u, data_test, result, sample_size):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    data_test['id_tmp'] = data_test['id'].apply(lambda x: str(x) + \"-\" + str(0))\n",
        "    model_score = 0\n",
        "    for cus in result.index:\n",
        "        if cus in data_test.id_tmp.values:\n",
        "            model_score = model_score +1\n",
        "            \n",
        "    random_sample_score = []\n",
        "    for _ in range(100):\n",
        "        tmp = 0\n",
        "        sample = data_u.sample(sample_size)\n",
        "        for cus in sample.index:\n",
        "            if cus in data_test.id_tmp.values:\n",
        "                tmp = tmp + 1\n",
        "        random_sample_score.append(tmp)\n",
        "\n",
        "    random_sample_score = np.mean(random_sample_score)\n",
        "#     random_sample_score = 24\n",
        "    print(time.time() - start_time)\n",
        "    \n",
        "    return(model_score, random_sample_score)\n",
        "  \n",
        "    \n",
        "# Run model\n",
        "#=============================================================#\n",
        "\n",
        "  data_test, query = query_data('2018-05-13', positive = True)\n",
        "  data, data_u, phone_list = get_data('2018-05-13')\n",
        "  result, size = ensemble_train_data(data, ratio=0.5, size=11000)\n",
        "  print(test_model(data_u, data_test, result, size))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}